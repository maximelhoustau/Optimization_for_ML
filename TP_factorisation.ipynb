{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TP fait en binome avec Gabriel Ballot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "#n images of p pixels\n",
    "n = 400;\n",
    "p = 10304;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix_from_faces(folder='att_faces', minidata=False):\n",
    "    # load images\n",
    "    # 400 images of size (112, 92)\n",
    "    M = []\n",
    "    if minidata is True:\n",
    "        nb_subjects = 1\n",
    "    else:\n",
    "        nb_subjects = 40\n",
    "    for subject in range(1, nb_subjects + 1\n",
    "                        ):\n",
    "        for image in range(1, 11):\n",
    "            face = plt.imread(folder + '/s' + str(subject)\n",
    "                              + '/' + str(image) + '.pgm')\n",
    "            M.append(face.ravel())\n",
    "\n",
    "    return np.array(M, dtype=float)\n",
    "\n",
    "def vectorize(W, H):\n",
    "    return np.concatenate((W.ravel(), H.ravel()))\n",
    "\n",
    "def unvectorize_M(W_H, M):\n",
    "    # number of elements in W_H is (n+p)*k where M is of size n x m\n",
    "    # W has the nk first elements\n",
    "    # H has the kp last elements\n",
    "    n, p = M.shape\n",
    "    k = W_H.shape[0] // (n + p)\n",
    "    W = W_H[:n * k].reshape((n, k))\n",
    "    H = W_H[n * k:].reshape((k, p))\n",
    "    return W, H\n",
    "\n",
    "# Small data to test the algorithm\n",
    "M_s = build_matrix_from_faces(folder='att_faces', minidata=True)\n",
    "def unvectorize(W_H): return unvectorize_M(W_H, M)\n",
    "k_s = 2\n",
    "\n",
    "# Full data\n",
    "M = build_matrix_from_faces(folder='att_faces', minidata=False)\n",
    "def unvectorize(W_H): return unvectorize_M(W_H, M)\n",
    "k = 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are 10 pictures of the face of 40 different people so in total we have 400 pictures. Each picture is 92x112 pixels, with 256 grey levels per pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Presentation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2-1\n",
    "\n",
    "Show that the objective function is not convex. Calculate its gradient. Is the gradient Lipschitz continuous?\n",
    "\n",
    "**Non convexity :**\n",
    "\n",
    "Let  $\\;\\tilde{f}:x,y \\mapsto (1-xy)^2$.  \n",
    "We have,\n",
    "\\begin{align}\n",
    "\\tilde{f}(0,0)&=1 \\\\\n",
    "\\tilde{f}(1,1)&=0 \\\\\n",
    "\\tilde{f}(-1,-1)&=0 \\\\\n",
    "\\end{align}  \n",
    "with,\n",
    "$$(0,0) = \\frac{1}{2}(1,1)+\\frac{1}{2}(-1,-1)$$\n",
    "and,\n",
    "$$\\tilde{f}(0,0) > \\frac{1}{2}\\tilde{f}(1,1)+\\frac{1}{2}\\tilde{f}(-1,-1)$$\n",
    "Thus, $\\tilde{f}$ is not convexe.\n",
    "\n",
    "Then, \n",
    "$$ \\tilde{f}(x, y) = f(0,\\dots,0,x,0,\\dots,0,y,0\\dots,0) $$\n",
    "\n",
    "This is why f is not convexe.\n",
    "\n",
    "**Gradient :**\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial f}{\\partial W_{a,b}} &= \\frac{1}{2np} \\sum_{i=1}^n \\sum_{l=1}^p 2(M_{i,l}-[WH]_{i,l})\\frac{\\partial}{\\partial W_{a,b}} \\Big( -\\sum_{j=1}^k W_{i,j}H_{j,l} \\Big) \\\\\n",
    "&= -\\frac{1}{2np} \\sum_{i=1}^n \\sum_{l=1}^p 2(M_{i,l}-[WH]_{i,l}) \\delta_{i,a} \\delta_{j,b} H_{b,l} \\\\\n",
    "&= -\\frac{1}{np} \\sum_{l=1}^p (M_{a,l}-[WH]_{a,l}) H_{b,l} \\\\\n",
    "&= -\\frac{1}{np} [M-WH]_a [H]_b^T \\\\\n",
    "\\\\\n",
    "\\frac{\\partial f}{\\partial H_{a,b}} &= \\frac{1}{2np} \\sum_{i=1}^n \\sum_{l=1}^p 2(M_{i,l}-[WH]_{i,l})\\frac{\\partial}{\\partial H_{a,b}} \\Big( -\\sum_{j=1}^k W_{i,j}H_{j,l} \\Big) \\\\\n",
    "&= -\\frac{1}{2np} \\sum_{i=1}^n \\sum_{l=1}^p 2(M_{i,l}-[WH]_{i,l}) \\delta_{l,b} \\delta_{j,a} W_{i,a} \\\\\n",
    "&= -\\frac{1}{np} \\sum_{i=1}^n (M_{i,b}-[WH]_{i,b}) W_{i,a} \\\\\n",
    "&= -\\frac{1}{np} [W^T]_a [M-WH]_b^T  \\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\Delta f&= \\frac{1}{np}\\begin{pmatrix}\n",
    "[M-WH]_1 [H]_1^T \\\\\n",
    "\\vdots \\\\\n",
    "[M-WH]_n [H]_k^T\\\\\n",
    "[W^T]_1 [M-WH]_1^T \\\\\n",
    "\\vdots \\\\\n",
    "[W^T]_k [M-WH]_n^T \\\\\n",
    "\\end{pmatrix} \\\\\n",
    "\\end{align}\n",
    "\n",
    "**$\\Delta f$ is not Lipschitz continuous :**\n",
    "\n",
    "The gradient is proportionnal to $WHH^T$, It can't be majored by a affine plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Find W when H0 is fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization of the optimization problem\n",
    "W0, S, H0 = scipy.sparse.linalg.svds(M, k);\n",
    "W0 = np.maximum(0, W0 * np.sqrt(S));\n",
    "H0 = np.maximum(0,(H0.T * np.sqrt(S)).T);\n",
    "\n",
    "#Initialization of the optimization problem (small matrix)\n",
    "W0_s, S_s, H0_s = scipy.sparse.linalg.svds(M_s, k_s);\n",
    "W0_s = np.maximum(0, W0_s * np.sqrt(S_s));\n",
    "H0_s = np.maximum(0,(H0_s.T * np.sqrt(S_s)).T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is clever to use this initialization beacause the svd function gives exactly what we need: M = W0*S*H0 = (W0*sqrt(S)) * (sqrt(S)*H0)\n",
    "\n",
    "##### Taking H0 as a constant, the gradient will become Lipschitz-continuous "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g(W) = \\frac{1}{2np}||M-WH_0||_F^2 $$\n",
    "\\begin{align}\n",
    "g(W+w) &= \\frac{1}{2np}||M-WH_0 +wH_0||_F^2 \\\\\n",
    "g(W+w) &= \\frac{1}{2np}(||M-WH_0||_F^2 + ||wH_0||_F^2 + 2<M-WH_0,wH_0>_F) \\\\\n",
    "g(W+w) &= g(W) + 2<(M-WH_0)H_0^T,w>_F +o(||wH_0||_F^2)) \\\\\n",
    "\\end{align}\n",
    "So,\n",
    "$$ \\Delta g = 2(M-WH_0)H_0^T $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(W):\n",
    "    X = M - np.dot(W,H0)\n",
    "    return np.trace(np.dot(X,X.T))/(2*n*p)\n",
    "\n",
    "def grad_g(W):\n",
    "    tmp= 2*(M - np.dot(W, H0));\n",
    "    return np.dot(tmp, np.transpose(H0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of $\\text{prox}_{\\gamma \\mathbb{1}_{\\mathbb{R}_+}}$.\n",
    "\n",
    "\\begin{align}\n",
    "\\text{prox}_{\\gamma i_{\\mathbb{R}_+}}(x) &= {\\text{argmin}}_{y\\in \\mathbb{R}} (\\gamma i_{\\mathbb{R}_+} + \\frac{1}{2}||y-x||^2) \\\\\n",
    "&= {\\text{argmin}}_{y\\in \\mathbb{R}^+} (\\frac{1}{2}||y-x||^2) \\\\\n",
    "&= \\text{proj}_{\\mathbb{R}^+}(x)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to minimize $g$ subject to non negativity constraints. This is equivalent to minimize :\n",
    "\n",
    "$$ g + \\iota_{\\mathbb{R}_+} $$\n",
    "\n",
    "because this function is equals to $+\\infty$ on $]-\\infty,0[$.\n",
    "\n",
    "Has $g$ has a Lipschitz gradient, we can use the proximal gradient method to compute \n",
    "\n",
    "$$min_{W \\in \\mathbb{R}} \\;\\; g(W) + \\iota_{\\mathbb{R}_+}(W) $$\n",
    "\n",
    "At each step, $W_{k+1}$ is given by\n",
    "\n",
    "$$ W_{k+1} = \\text{prox}_{\\gamma_k \\iota_{\\mathbb{R}_+}}\\big( W_k - \\gamma_k \\nabla g(W_k)\\big) $$\n",
    "\n",
    "with $\\gamma_k > 0$ the step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_gradient_method(val_g, grad_g, W0, gamma, N):\n",
    "    for i in range(N) :\n",
    "        tmp = W0 - gamma * grad_g(W0)\n",
    "        W0 = np.maximum(0,tmp)\n",
    "    return W0, val_g(W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H0_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-db31a28f80dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lipschitz constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH0_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH0_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'H0_s' is not defined"
     ]
    }
   ],
   "source": [
    "Ls = np.linalg.norm(np.dot(np.transpose(H0_s), H0_s))\n",
    "print(Ls)\n",
    "t = time()\n",
    "mini = projected_gradient_method(g, grad_g, W0, 1, 100)\n",
    "print(\"W_min = \", mini[0])\n",
    "print(\"\\ng(W_min) = \", mini[1])\n",
    "print(\"time : \",time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Algorithmic refinement for the problem with H0 fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Projected gradient method with line search\n",
    "def line_search_projected_gradient_method(val_g, grad_g, W0, gamma, N):\n",
    "    for i in range(N) :\n",
    "        f = lambda gamma : val_g(W0 - gamma * grad_g(W0))\n",
    "        gamma = minimize_scalar(f).x\n",
    "        W0 = np.maximum(0, W0 - gamma * grad_g(W0))\n",
    "    return W0, val_g(W0)\n",
    "\n",
    "t = time()\n",
    "mini = line_search_projected_gradient_method(g, grad_g, W0, 1, 100)\n",
    "print(\"W_min = \", mini[0])\n",
    "print(\"\\ng(W_min) = \", mini[1])\n",
    "print(\"time : \",time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second algorithm gives a better minimum (instead of 534). Nevertheless, it takes a lot more time (166 seconds instead of 6.5 seconds).\n",
    "We could use an approximate line search to be quicker."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
